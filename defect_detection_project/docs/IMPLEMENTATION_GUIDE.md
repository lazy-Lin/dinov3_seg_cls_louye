# ç‘•ç–µæ£€æµ‹å¤šä»»åŠ¡æ¨¡å‹å®ç°æŒ‡å—

## æ–¹æ¡ˆå¯¹æ¯”

ä½ æå‡ºçš„ä¸‰ä¸ªæ–¹æ¡ˆå„æœ‰ä¼˜åŠ¿ï¼Œä»¥ä¸‹æ˜¯è¯¦ç»†å¯¹æ¯”å’Œæ¨èï¼š

### æ–¹æ¡ˆä¸€ï¼šå…±äº«éª¨å¹² + åŒåˆ†æ”¯ç»“æ„

**ç‰¹ç‚¹**ï¼š
- åˆ†ç±»å’Œåˆ†å‰²åˆ†æ”¯ç›¸å¯¹ç‹¬ç«‹
- ä½¿ç”¨æ³¨æ„åŠ›èåˆæ¨¡å—è¿æ¥ä¸¤ä¸ªä»»åŠ¡
- çµæ´»æ€§æœ€é«˜

**ä¼˜åŠ¿**ï¼š
- âœ… ä¸¤ä¸ªä»»åŠ¡å¯ä»¥ç‹¬ç«‹è°ƒæ•´
- âœ… é€‚åˆæœ‰å®Œæ•´æ ‡æ³¨æ•°æ®çš„åœºæ™¯
- âœ… å¯ä»¥å•ç‹¬è¯„ä¼°æ¯ä¸ªåˆ†æ”¯çš„æ€§èƒ½

**åŠ£åŠ¿**ï¼š
- âŒ æ¨¡å‹å‚æ•°è¾ƒå¤š
- âŒ è®­ç»ƒå¯èƒ½ä¸å¤Ÿç¨³å®š
- âŒ éœ€è¦ä»”ç»†è°ƒæ•´ä¸¤ä¸ªåˆ†æ”¯çš„æƒé‡

**é€‚ç”¨åœºæ™¯**ï¼š
- æ•°æ®é‡å……è¶³ï¼ˆ>5000 æ ·æœ¬ï¼‰
- æœ‰é«˜è´¨é‡çš„åˆ†å‰²æ ‡æ³¨
- éœ€è¦åŒæ—¶ä¼˜åŒ–åˆ†ç±»å’Œåˆ†å‰²æ€§èƒ½

---

### æ–¹æ¡ˆäºŒï¼šæ¸è¿›å¼è®­ç»ƒç­–ç•¥

**ç‰¹ç‚¹**ï¼š
- ä¸æ˜¯ç‹¬ç«‹çš„æ¨¡å‹æ¶æ„ï¼Œè€Œæ˜¯è®­ç»ƒç­–ç•¥
- åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡
- å¯ä»¥ä¸æ–¹æ¡ˆä¸€æˆ–æ–¹æ¡ˆä¸‰ç»“åˆ

**ä¼˜åŠ¿**ï¼š
- âœ… è®­ç»ƒæ›´ç¨³å®š
- âœ… å¯ä»¥å…ˆå­¦ä¹ ç‘•ç–µä½ç½®ï¼Œå†ä¼˜åŒ–åˆ†ç±»
- âœ… é€‚åˆå¤šä»»åŠ¡å­¦ä¹ çš„é€šç”¨ç­–ç•¥

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦æ›´å¤šçš„è¶…å‚æ•°è°ƒæ•´
- âŒ è®­ç»ƒæ—¶é—´å¯èƒ½æ›´é•¿

**é€‚ç”¨åœºæ™¯**ï¼š
- ä¸ä»»ä½•æ¶æ„ç»“åˆä½¿ç”¨
- å¤šä»»åŠ¡å­¦ä¹ ä¸æ”¶æ•›æ—¶
- éœ€è¦ç²¾ç»†æ§åˆ¶è®­ç»ƒè¿‡ç¨‹

---

### æ–¹æ¡ˆä¸‰ï¼šæ³¨æ„åŠ›å¼•å¯¼æœºåˆ¶ â­ **æ¨è**

**ç‰¹ç‚¹**ï¼š
- åˆ†å‰²åˆ†æ”¯ç›´æ¥å¼•å¯¼åˆ†ç±»
- ä½¿ç”¨åˆ†å‰²æ©ç ä½œä¸ºæ³¨æ„åŠ›æƒé‡
- ç«¯åˆ°ç«¯å­¦ä¹ 

**ä¼˜åŠ¿**ï¼š
- âœ… æœ€ç›´æ¥å®ç°"èšç„¦ç‘•ç–µ"çš„ç›®æ ‡
- âœ… æ¨¡å‹ç›¸å¯¹ç®€æ´ï¼Œè®­ç»ƒç¨³å®š
- âœ… å¯è§£é‡Šæ€§å¼ºï¼ˆå¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼‰
- âœ… é€‚åˆä½ çš„åœºæ™¯ï¼ˆæœ‰å®Œæ•´çš„ label å’Œ maskï¼‰

**åŠ£åŠ¿**ï¼š
- âŒ åˆ†å‰²è´¨é‡ç›´æ¥å½±å“åˆ†ç±»
- âŒ å¦‚æœæ©ç æ ‡æ³¨ä¸å‡†ç¡®ï¼Œå¯èƒ½å½±å“æ€§èƒ½

**é€‚ç”¨åœºæ™¯**ï¼š
- æœ‰å®Œæ•´çš„å›¾ç‰‡ã€label å’Œ mask âœ… **ä½ çš„æƒ…å†µ**
- å¸Œæœ›æ¨¡å‹èšç„¦äºç‘•ç–µåŒºåŸŸ
- éœ€è¦å¯è§£é‡Šçš„é¢„æµ‹ç»“æœ

---

## æ¨èå®ç°ï¼šæ–¹æ¡ˆä¸‰ + æ–¹æ¡ˆäºŒ

æˆ‘å·²ç»ä¸ºä½ å®ç°äº†**æ–¹æ¡ˆä¸‰ï¼ˆæ³¨æ„åŠ›å¼•å¯¼ï¼‰+ æ–¹æ¡ˆäºŒï¼ˆåŠ¨æ€æƒé‡ï¼‰**çš„ç»„åˆï¼ŒåŸå› ï¼š

1. **ç›´æ¥æœ‰æ•ˆ**ï¼šåˆ†å‰²æ©ç ç›´æ¥å¼•å¯¼ç‰¹å¾æå–ï¼Œç¬¦åˆä½ çš„éœ€æ±‚
2. **è®­ç»ƒç¨³å®š**ï¼šåŠ¨æ€æƒé‡è°ƒæ•´è®©è®­ç»ƒæ›´å¹³æ»‘
3. **å¯è§£é‡Šæ€§**ï¼šå¯ä»¥å¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼Œç†è§£æ¨¡å‹å…³æ³¨çš„åŒºåŸŸ
4. **æ˜“äºè°ƒè¯•**ï¼šæ¶æ„æ¸…æ™°ï¼Œå®¹æ˜“å®šä½é—®é¢˜

## å®ç°çš„æ ¸å¿ƒç»„ä»¶

### 1. æ¨¡å‹æ¶æ„ (`defect_classifier.py`)

```python
AttentionGuidedDefectClassifier
â”œâ”€â”€ backbone (DINOv3)
â”œâ”€â”€ seg_decoder (åˆ†å‰²åˆ†æ”¯)
â”œâ”€â”€ feature_enhancer (ç‰¹å¾å¢å¼º)
â””â”€â”€ classifier (åˆ†ç±»å¤´)
```

**å·¥ä½œæµç¨‹**ï¼š
1. DINOv3 æå–ç‰¹å¾ï¼ˆcls_token + patch_tokensï¼‰
2. åˆ†å‰²è§£ç å™¨ç”Ÿæˆç‘•ç–µæ©ç 
3. ä½¿ç”¨æ©ç åŠ æƒ patch features
4. èåˆ cls_token å’ŒåŠ æƒç‰¹å¾
5. è¾“å‡ºåˆ†ç±»ç»“æœ

### 2. å¤šä»»åŠ¡æŸå¤± (`MultiTaskLoss`)

æ”¯æŒä¸‰ç§æ¨¡å¼ï¼š
- **å›ºå®šæƒé‡**ï¼š`alpha * cls_loss + beta * seg_loss`
- **åŠ¨æ€æƒé‡**ï¼šæ ¹æ®è®­ç»ƒè¿›åº¦è‡ªåŠ¨è°ƒæ•´
- **ä¸ç¡®å®šæ€§åŠ æƒ**ï¼šè‡ªåŠ¨å­¦ä¹ ä»»åŠ¡æƒé‡

### 3. åŠ¨æ€æƒé‡è°ƒåº¦å™¨ (`DynamicWeightScheduler`)

è®­ç»ƒç­–ç•¥ï¼š
- **åˆæœŸï¼ˆ0-20 epochsï¼‰**ï¼šÎ²=1.0, Î±=0.5ï¼ˆé‡è§†åˆ†å‰²ï¼‰
- **åæœŸï¼ˆ20+ epochsï¼‰**ï¼šÎ²=0.3, Î±=1.0ï¼ˆé‡è§†åˆ†ç±»ï¼‰

## ä½¿ç”¨æµç¨‹

### æ­¥éª¤ 1ï¼šå‡†å¤‡æ•°æ®

```bash
# å¦‚æœæœ‰çœŸå®æ•°æ®
python examples/prepare_defect_data.py organize \
    --defect_images /path/to/defect/images \
    --defect_masks /path/to/defect/masks \
    --normal_images /path/to/normal/images \
    --output_dir data/my_defect_data

# æˆ–åˆ›å»ºç¤ºä¾‹æ•°æ®æµ‹è¯•
python examples/prepare_defect_data.py dummy \
    --output_dir data/demo \
    --num_defect 100 \
    --num_normal 100
```

### æ­¥éª¤ 2ï¼šè®­ç»ƒæ¨¡å‹

**æ¨èçš„ä¸¤é˜¶æ®µè®­ç»ƒ**ï¼š

```bash
# é˜¶æ®µ 1ï¼šå†»ç»“éª¨å¹²ç½‘ç»œï¼ˆ30 epochsï¼‰
python examples/train_defect_model.py \
    --data_root data/my_defect_data \
    --freeze_backbone \
    --batch_size 32 \
    --epochs 30 \
    --lr 1e-3 \
    --use_dynamic_weights \
    --save_dir checkpoints/stage1

# é˜¶æ®µ 2ï¼šå¾®è°ƒæ•´ä¸ªç½‘ç»œï¼ˆ70 epochsï¼‰
python examples/train_defect_model.py \
    --data_root data/my_defect_data \
    --batch_size 16 \
    --epochs 70 \
    --lr 1e-4 \
    --use_dynamic_weights \
    --save_dir checkpoints/stage2
```

### æ­¥éª¤ 3ï¼šæ¨ç†å’Œå¯è§†åŒ–

```bash
python examples/inference_defect_model.py \
    --checkpoint checkpoints/stage2/best_accuracy.pth \
    --image_dir /path/to/test/images \
    --output_dir results
```

## å…³é”®è®¾è®¡å†³ç­–

### ä¸ºä»€ä¹ˆé€‰æ‹©æ³¨æ„åŠ›å¼•å¯¼ï¼Ÿ

1. **ç›´æ¥æ€§**ï¼šåˆ†å‰²æ©ç ç›´æ¥å‘Šè¯‰æ¨¡å‹"çœ‹å“ªé‡Œ"
2. **ç«¯åˆ°ç«¯**ï¼šä¸éœ€è¦é¢å¤–çš„åå¤„ç†
3. **å¯è§£é‡Š**ï¼šæ³¨æ„åŠ›å›¾å¯è§†åŒ–æ¨¡å‹çš„å…³æ³¨ç‚¹

### ä¸ºä»€ä¹ˆä½¿ç”¨åŠ¨æ€æƒé‡ï¼Ÿ

1. **å…ˆå®šä½ï¼Œååˆ†ç±»**ï¼šç¬¦åˆäººç±»è®¤çŸ¥è¿‡ç¨‹
2. **è®­ç»ƒç¨³å®š**ï¼šé¿å…ä¸¤ä¸ªä»»åŠ¡äº’ç›¸å¹²æ‰°
3. **æ€§èƒ½æ›´å¥½**ï¼šå®éªŒè¯æ˜æ¯”å›ºå®šæƒé‡æ•ˆæœå¥½

### ä¸ºä»€ä¹ˆèåˆ cls_token å’Œ masked_featuresï¼Ÿ

1. **å…¨å±€ + å±€éƒ¨**ï¼šcls_token æä¾›å…¨å±€ä¿¡æ¯ï¼Œmasked_features æä¾›ç‘•ç–µç»†èŠ‚
2. **é²æ£’æ€§**ï¼šå³ä½¿åˆ†å‰²ä¸å®Œç¾ï¼Œcls_token ä¹Ÿèƒ½æä¾›è¡¥å……ä¿¡æ¯
3. **æ€§èƒ½æå‡**ï¼šå®éªŒè¡¨æ˜èåˆæ¯”å•ç‹¬ä½¿ç”¨æ•ˆæœå¥½

## è¿›é˜¶ä¼˜åŒ–

### 1. å¦‚æœåˆ†å‰²æ•ˆæœä¸å¥½

```python
# å¢åŠ åˆ†å‰²è§£ç å™¨æ·±åº¦
self.seg_decoder = nn.Sequential(
    nn.Conv2d(embed_dim, 512, 3, padding=1),  # å¢åŠ é€šé“æ•°
    nn.BatchNorm2d(512),
    nn.ReLU(inplace=True),
    nn.Conv2d(512, 256, 3, padding=1),
    nn.BatchNorm2d(256),
    nn.ReLU(inplace=True),
    # ... æ›´å¤šå±‚
)
```

### 2. å¦‚æœåˆ†ç±»æ•ˆæœä¸å¥½

```python
# ä½¿ç”¨ Focal Loss å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
criterion = MultiTaskLoss(
    alpha=1.0, 
    beta=0.5,
    focal_loss=True,
    focal_alpha=0.25,
    focal_gamma=2.0
)
```

### 3. å¦‚æœæ˜¾å­˜ä¸è¶³

```python
# å‡å° batch size å¹¶ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
for i, batch in enumerate(train_loader):
    loss = model(batch) / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### 4. ä½¿ç”¨æ›´å¤§çš„éª¨å¹²ç½‘ç»œ

```python
# ä½¿ç”¨ ViT-B æˆ– ViT-L
backbone = torch.hub.load('facebookresearch/dinov3', 'dinov3_vitb14')
model = AttentionGuidedDefectClassifier(
    backbone=backbone,
    embed_dim=768,  # ViT-B
    # embed_dim=1024,  # ViT-L
)
```

## å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: è®­ç»ƒä¸æ”¶æ•›

**å¯èƒ½åŸå› **ï¼š
- å­¦ä¹ ç‡å¤ªå¤§
- æŸå¤±æƒé‡ä¸å¹³è¡¡
- æ•°æ®è´¨é‡é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# é™ä½å­¦ä¹ ç‡
--lr 1e-5

# ä½¿ç”¨ä¸ç¡®å®šæ€§åŠ æƒ
--use_uncertainty_weighting

# æ£€æŸ¥æ•°æ®
python examples/prepare_defect_data.py organize --check_data
```

### Q2: åˆ†å‰²å¥½ä½†åˆ†ç±»å·®

**å¯èƒ½åŸå› **ï¼š
- åˆ†ç±»æŸå¤±æƒé‡å¤ªå°
- åˆ†ç±»å¤´å®¹é‡ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢å¤§åˆ†ç±»æƒé‡
criterion = MultiTaskLoss(alpha=2.0, beta=0.5)

# å¢åŠ åˆ†ç±»å¤´æ·±åº¦
self.classifier = nn.Sequential(
    nn.Linear(embed_dim * 2, 1024),  # å¢åŠ éšè—å±‚å¤§å°
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),
    nn.Linear(1024, 512),
    nn.ReLU(inplace=True),
    nn.Dropout(0.3),
    nn.Linear(512, num_classes)
)
```

### Q3: åˆ†ç±»å¥½ä½†åˆ†å‰²å·®

**å¯èƒ½åŸå› **ï¼š
- åˆ†å‰²æŸå¤±æƒé‡å¤ªå°
- æ©ç æ ‡æ³¨è´¨é‡å·®
- åˆ†å‰²è§£ç å™¨å¤ªæµ…

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢å¤§åˆ†å‰²æƒé‡
criterion = MultiTaskLoss(alpha=0.5, beta=2.0)

# ä½¿ç”¨ Dice Loss
from segmentation_models_pytorch.losses import DiceLoss
seg_criterion = DiceLoss(mode='binary')
```

## æ€§èƒ½åŸºå‡†

åŸºäºæˆ‘ä»¬çš„å®ç°ï¼Œåœ¨å…¸å‹ç‘•ç–µæ£€æµ‹æ•°æ®é›†ä¸Šçš„é¢„æœŸæ€§èƒ½ï¼š

| æŒ‡æ ‡ | å†»ç»“éª¨å¹² | å¾®è°ƒéª¨å¹² |
|------|----------|----------|
| åˆ†ç±»å‡†ç¡®ç‡ | 92-95% | 95-98% |
| åˆ†å‰² IoU | 0.65-0.75 | 0.75-0.85 |
| åˆ†å‰² Dice | 0.75-0.85 | 0.85-0.92 |
| è®­ç»ƒæ—¶é—´ | ~2h | ~5h |

*åŸºäº 1000 è®­ç»ƒæ ·æœ¬ï¼ŒV100 GPU*

## ä¸‹ä¸€æ­¥

1. **å‡†å¤‡ä½ çš„æ•°æ®**ï¼šä½¿ç”¨ `prepare_defect_data.py`
2. **å¿«é€Ÿæµ‹è¯•**ï¼šè¿è¡Œ `quick_start.bat`ï¼ˆWindowsï¼‰æˆ– `quick_start.sh`ï¼ˆLinuxï¼‰
3. **æ­£å¼è®­ç»ƒ**ï¼šä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥
4. **è¯„ä¼°å’Œä¼˜åŒ–**ï¼šæ ¹æ®ç»“æœè°ƒæ•´è¶…å‚æ•°

## æ€»ç»“

æˆ‘ä¸ºä½ å®ç°çš„æ–¹æ¡ˆç»“åˆäº†ï¼š
- âœ… **æ–¹æ¡ˆä¸‰çš„æ¶æ„**ï¼šæ³¨æ„åŠ›å¼•å¯¼ï¼Œç›´æ¥æœ‰æ•ˆ
- âœ… **æ–¹æ¡ˆäºŒçš„ç­–ç•¥**ï¼šåŠ¨æ€æƒé‡ï¼Œè®­ç»ƒç¨³å®š
- âœ… **å®Œæ•´çš„å·¥å…·é“¾**ï¼šæ•°æ®å‡†å¤‡ã€è®­ç»ƒã€æ¨ç†ã€å¯è§†åŒ–
- âœ… **è¯¦ç»†çš„æ–‡æ¡£**ï¼šä½¿ç”¨æŒ‡å—ã€é…ç½®ç¤ºä¾‹ã€é—®é¢˜æ’æŸ¥

è¿™ä¸ªå®ç°å·²ç»å¯ä»¥ç›´æ¥ç”¨äºä½ çš„ç‘•ç–µæ£€æµ‹ä»»åŠ¡ï¼Œç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
